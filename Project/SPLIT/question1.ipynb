{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import set_config\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TJ_0Joi7uv-"
   },
   "source": [
    "### Question 1 : How can we know if we had bought a great deal (Our team will create a model to predict price of watch) \n",
    "Have you ever wanted to buy a watch but you do not know that the price of the thing that you found is cheap or expensive. That is the reason why we want to ask this question is that our team was in this situations multiple times. We find that it is really time consuming when you have to find the things which we want to buy at a good price. Therefore, we will create a model that can help us and other people who want to buy Rolex save time from searching for a great deal. And if we can solve this problem, we can use this model to predict price of various things not only Rolex watches."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class to preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gnGZd2C27uv-"
   },
   "outputs": [],
   "source": [
    "class preprocess(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform (self, X_df):\n",
    "        out_df = X_df.copy()\n",
    "    \n",
    "        #Remove watch's size in model name\n",
    "        out_df['model'].replace(regex = True,to_replace = r\"[0-9]\",value = '',inplace= True)\n",
    "\n",
    "        # #Get true size of case\n",
    "        out_df['case diameter'] = out_df['case diameter'].str.extract(r'(^[\\d][\\d])')\n",
    "\n",
    "        #Preprocess ref number because some ref num are in wrong format (including characters,etc) \n",
    "\n",
    "        tmp = out_df['reference number'].str.extract(r'(\\d+[-]\\d+)|(\\d+)')\n",
    "        tmp[0].fillna(tmp[1],inplace=True)\n",
    "        out_df['reference number'] = tmp[0]\n",
    "\n",
    "        #Replace all Nan with Unknown\n",
    "        out_df['reference number'].replace(regex = True,to_replace = \"\",value = 'Unknown',inplace= True)\n",
    "\n",
    "        out_df['year of production'] = out_df['year of production'].astype(np.number)\n",
    "        out_df.loc[out_df['year of production'] < 1905, 'year of production' ] = np.nan\n",
    "        out_df['year of production'] = out_df['year of production'].astype('object')\n",
    "\n",
    "        model_list = out_df['model'].unique()\n",
    "        for i in model_list:\n",
    "            try:\n",
    "                out_df[out_df['model'] == i]['price'].fillna(value = out_df[out_df['model'] == i]['price'].mean())\n",
    "            except:\n",
    "                pass\n",
    "            try :\n",
    "                out_df[out_df['model'] == i] = out_df[out_df['model'] == i].fillna(out_df[out_df['model'] == i].mode().iloc[0])\n",
    "            except:\n",
    "                pass\n",
    "        return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2MvBQss7uv-"
   },
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the initial state of rolex_df with the same state as the one in the explore notebook\n",
    "rolex_df = pd.read_csv('../rolex_scaper_clean.csv')\n",
    "rolex_df.drop_duplicates(inplace=True)\n",
    "rolex_df['year of production'] = rolex_df['year of production'].astype('object')\n",
    "rolex_df.drop(columns = ['ad name'],inplace=True)\n",
    "rolex_df = rolex_df[rolex_df['model'] != 'Rolex']\n",
    "rolex_df.reset_index(drop=True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KSlz62DV7uv_"
   },
   "outputs": [],
   "source": [
    "tmp  = rolex_df[['model', 'reference number', 'price',\n",
    "       'movement', 'case material', 'case diameter', 'year of production',\n",
    "       'condition', 'scope of delivery']].copy()\n",
    "\n",
    "X_train, X_test= train_test_split(tmp, test_size=0.2, random_state=0)\n",
    "X_train = preprocess().transform(X_train)\n",
    "Y_train = X_train['price']\n",
    "X_train.drop(\"price\", axis=1,inplace=True)\n",
    "\n",
    "X_test = preprocess().transform(X_test)\n",
    "Y_test = X_test['price']\n",
    "X_test.drop(\"price\", axis=1,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipleline \n",
    "- For categorical columns, we use one hot encoding to convert it to numerical form and then scale it by using Standard Scaler.\n",
    "- For numeric columns, we use Standard Scaler to normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9nJpxiEj7uv_"
   },
   "outputs": [],
   "source": [
    "categorical_cols = X_train.select_dtypes(exclude=np.number).columns\n",
    "numerical_cols = X_train.select_dtypes(include = np.number).columns\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numerics_pipeline = make_pipeline(scaler)\n",
    "categorical_pipeline = make_pipeline(ohe,scaler)\n",
    "\n",
    "col_transformer = make_column_transformer(\n",
    "    (numerics_pipeline,numerical_cols),\n",
    "    (categorical_pipeline,categorical_cols),\n",
    "    remainder='passthrough')\n",
    "preprocess_pipeline = make_pipeline(preprocess(), col_transformer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bWibPIE67uv_"
   },
   "source": [
    "Predict\n",
    "\n",
    "After using hyper tunning to choose best parameters we go with this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GwAKBWq7uwA",
    "outputId": "ad6f26ca-a000-4ed2-a593-8e3b253b8677"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   30.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "full_pipeline = make_pipeline(preprocess_pipeline,RandomForestRegressor(n_jobs = -1,max_features = 'sqrt',max_depth = 60,verbose = True))\n",
    "clf = full_pipeline.fit(X_train,Y_train)\n",
    "predict_y = clf.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5bcdtIl7uwA",
    "outputId": "a1f70df3-77b3-4333-8d7e-9d4a4d2c2392"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17236.921112302633"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from math import sqrt\n",
    "sqrt(mean_squared_error(predict_y, Y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R^2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_T6m4e6yFY3",
    "outputId": "16eba952-0209-4b55-c305-8ec3e4d69a2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770987195526994"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y_test,predict_y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pt53RuJn28AS",
    "outputId": "04c18a99-b762-4f1c-94e5-7fd2f01b9ff3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6770987195526994"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,Y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UXZt7Ct28LRQ",
    "outputId": "92ea5909-220a-4985-d95e-b5915970890f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8600063449729457"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,Y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price of this watch is 12825$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rolex_test = pd.read_csv('../test_model.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([Rolex_test, X_test], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13077.723849904036"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(df3)[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy on test set is about **68% and on the training set is approximately 87%**. The model still gives an acceptable prediction on the price of the test watch, although the accuracy of our model on test set is not really high. The true price is `12825 USD` and the predicted price is about `12850 USD`, i think we can count on this model for the next time when we want to but a new Rolex. Basing on this model, when you buy a Rolex, you can know that if you are buying that watch for an acceptable price. Just like for the above watch, if you see price on its tag which is about 14000$ then you can know that its not worth and you can buy it for a better price (about blow `12800 USD`) in other stores. If you own the above watch for a price which is about below `12500 USD`, then congratulations you have an awesome deal.\n",
    "- We also tried to stack various models in order to increase the accuracy, but it only enhanced about 2-3% and took too long to run (about 2-3 hours running on Google Colab). That is the reason why on this report we only use the RandomForestRegressor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('min_ds-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29152f32b696e88688ca134027de37900a1f6ab9cc9c49a6b6f96b34c0652453"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
